{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638d840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\priya\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb00386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0a6ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#con is graph and we run it in session\n",
    "con=tf.constant('hello world')\n",
    "\n",
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f12091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello world'\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    output=sess.run(con)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd2690a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=\"test\"\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1bdacf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A is a 0-dimensional int32 tensor\n",
    "A=tf.constant(1234)\n",
    "\n",
    "#B is a 1-dimensional int32 tensor\n",
    "B=tf.constant([123,456,789])\n",
    "\n",
    "#C is a 2-dimensional int32 tensor\n",
    "C=tf.constant([[123,456,789],[987,654,321]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "086724d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    c1=tf.constant(4,dtype=tf.float64,name=\"c\")\n",
    "    c2=tf.constant(4,dtype=tf.int32,name=\"c\")\n",
    "print(c1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb0cd76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_1:0\n"
     ]
    }
   ],
   "source": [
    "print(c2.name)\n",
    "#as name is similar for c1 and c2 so first time c:0 and second time we c_1:0..1 teling about repetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cbdc5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0\n",
      "prefix_name/c:0\n",
      "prefix_name/c_1:0\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    c1=tf.constant(4,dtype=tf.float64,name='c')\n",
    "with tf.name_scope(\"prefix_name\"):\n",
    "    c2=tf.constant(4,dtype=tf.int32,name=\"c\")\n",
    "    c3=tf.constant(4,dtype=tf.float64,name=\"c\")\n",
    "    \n",
    "print(c1.name)\n",
    "print(c2.name)\n",
    "print(c3.name)\n",
    "\n",
    "\n",
    "#name_scope normally group all the values inside particular group together..by name prefix_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26280913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123, 456, 789],\n",
       "       [222, 333, 444]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=tf.constant([[123,456,789],[222,333,444]])\n",
    "sess=tf.Session()\n",
    "sess.run(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d392fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph is anything that has nodes and edges..here in tendorflow operations represent the node and data being passed represent \n",
    "#the edges\n",
    "#the nodes or operation are known as op function in tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f9c826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre run: \n",
      "<tf.Variable 'var:0' shape=(1, 5) dtype=float32_ref>\n",
      "post run: \n",
      "[[-0.55923957  0.6347584   0.50710994 -0.3458903   0.10109371]]\n"
     ]
    }
   ],
   "source": [
    "init_val=tf.random_normal((1,5),0,1)\n",
    "var=tf.Variable(init_val,name='var')\n",
    "print(\"pre run: \\n{}\".format(var))\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    post_var=sess.run(var)\n",
    "print(\"post run: \\n{}\".format(post_var))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ded4a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global varibales initializer it stores some memory in session so that we can change the value ..cache it and run it\n",
    "#every time we run we get random value for the post var as value of var changes due to random_normal\n",
    "#if we want to reuse the same varibale then tf.get_variables() function is used instead of tf.Variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd5fca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "#tf.placeholder()\n",
    "#this is where we would feed the data\n",
    "#tf.placeholder() returns a tensor that gets its value from data passed to the tf.session.run() function,allowing you to set the\n",
    "#input right before the session runs.\n",
    "\n",
    "x=tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output=sess.run(x,feed_dict={x:\"test\"})\n",
    "    print(output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d711520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test String\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "x=tf.placeholder(tf.string)\n",
    "y=tf.placeholder(tf.int32)\n",
    "z=tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output_x=sess.run(x,feed_dict={x:\"Test String\",y:123,z:45.67})\n",
    "    output_y=sess.run(y,feed_dict={x:\"Test String\",y:123,z:45.67})\n",
    "    print(output_x)\n",
    "    print(output_y)\n",
    "    \n",
    "#even if we are feeding everything we are getting x and y as output..which we have mentioned before feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b7e3900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4. 9.]\n"
     ]
    }
   ],
   "source": [
    "x=tf.placeholder(\"float\",None)\n",
    "y=x ** 2\n",
    "with tf.Session() as session:\n",
    "    result=session.run(y, feed_dict={x: [1,2,3]})\n",
    "print(result)\n",
    "#error because data passed to feed_dict doesn't match the tensor type and can't be cast into the tensor type,you wil get the error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47a14dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#tensorflow Math\n",
    "#..add here is an op function\n",
    "x=tf.add(5,2)\n",
    "with tf.Session() as sess:\n",
    "    re=sess.run(x)\n",
    "    print(re)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a826f8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "x=tf.subtract(15,2)\n",
    "y=tf.multiply(15,2)\n",
    "with tf.Session() as sess:\n",
    "    re1=sess.run(x)\n",
    "    re2=sess.run(y)\n",
    "    print(re1)\n",
    "    print(re2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceee67df",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Sub' Op has type int32 that does not match type float32 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    528\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[0;32m   1223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[1;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1017\u001b[0m         \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1018\u001b[1;33m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[0;32m   1019\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype int32: 'Tensor(\"Const_6:0\", shape=(), dtype=int32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c5168e933fa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mre3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#error becoz one value is float and other is int\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36msubtract\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  11572\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11573\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m> 11574\u001b[1;33m         \"Sub\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m  11575\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11576\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    561\u001b[0m                   \u001b[1;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[1;32m--> 563\u001b[1;33m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input 'y' of 'Sub' Op has type int32 that does not match type float32 of argument 'x'."
     ]
    }
   ],
   "source": [
    "z=tf.subtract(tf.constant(2.0),tf.constant(1))\n",
    "with tf.Session() as sess:\n",
    "    re3=sess.run(z)\n",
    "    print(re3)\n",
    "#error becoz one value is float and other is int\n",
    "#so we use something called tf.cast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ba7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will cast float to int using tf.cast\n",
    "c=tf.subtract(tf.cast(tf.constant(2.0),tf.int32),tf.constant(1))\n",
    "with tf.Session() as sess:\n",
    "    out=sess.run(c)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.constant(10)\n",
    "y=tf.constant(2)\n",
    "z=tf.subtract(tf.divide(x,y),1)\n",
    "with tf.Session() as sess:\n",
    "    re5=sess.run(z)\n",
    "    print(re5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9104677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow linear fucntion\n",
    "#tf.truncated_normal()function returns a tensor with random values from a normaldistribution whose magnitude is no more than 2\n",
    "#standard deviation from the mean\n",
    "#since weights are already helping prevent the model from getting stuck,you don't need to randomize the bias.Let's use the\n",
    "#simplest solution setting the bias to 0\n",
    "n_features=120\n",
    "n_labels=5\n",
    "weights=tf.Variable(tf.truncated_normal((n_features,n_labels)))\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25149e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels=5\n",
    "bias=tf.Variable(tf.zeros(n_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed dictionary\n",
    "#feed is used to tempropary replace the output of an operation with a tenszor value.The parameter feed_dict is used to override\n",
    "# the tensor values in the graph and it expects a python dictionary object as input.the keys in the dictionary are handles to\n",
    "#tensor objects that should be overridden while the values can be numbers,strings,lists or Numpy arrays.\n",
    "#feed_dict is also useful for specifying input values\n",
    "\n",
    "\n",
    "a=tf.add(2,5)\n",
    "b=tf.multiply(a,3)\n",
    "\n",
    "#startup a session using the default graph\n",
    "sess=tf.Session()\n",
    "\n",
    "#define the dictionary that says to replace the value of a with 15\n",
    "replace_dict={a:15}\n",
    "#run the session passing in \"replace-dict\" as the value to the feed_dict\n",
    "output=sess.run(b,feed_dict=replace_dict)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow softmax\n",
    "#We are using tensorflow to build the neural network and  there is a function to calculate softmax\n",
    "x=tf.nn.softmax([2.0,1.0,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb62d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_2():\n",
    "    output=None\n",
    "    logit_data=[19,354,354,45,354,54]\n",
    "    logits=tf.placeholder(tf.float32)\n",
    "    \n",
    "    softmax=tf.nn.softmax(logits)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        output=sess.run(softmax,feed_dict={logits:logit_data})\n",
    "        \n",
    "    return output\n",
    "print(run_2())\n",
    "#calculate the softmax of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorflow Cross entropy\n",
    "#To create a cross entropy function in Tensorflow,you will need to use 2 functions\n",
    "#tf.reduce_sum()\n",
    "#tf.log()\n",
    "x=tf.reduce_sum([1,2,3,4,5])\n",
    "#tf,reduce_sum..takes an array of numbers and sums them together.\n",
    "\n",
    "#Natural log..tf.log take natural log of number\n",
    "t=tf.log(100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4283ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.35667497\n"
     ]
    }
   ],
   "source": [
    "#print the cross entropy using softmax data and one_hot_encod_label\n",
    "softmax_data=[0.7,0.2,0.1]\n",
    "one_hot_data=[1.0,0.0,0.0]\n",
    "\n",
    "softmax=tf.placeholder(tf.float32)\n",
    "one_hot=tf.placeholder(tf.float32)\n",
    "\n",
    "# print cross entropy from session\n",
    "\n",
    "cross_entropy=tf.reduce_sum(tf.multiply(one_hot,tf.log(softmax)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output=sess.run(cross_entropy,feed_dict={one_hot:one_hot_data,softmax:softmax_data})\n",
    "    print(output)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e07c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST using tensorflow 1\n",
    "#Tf2 has eager execution which mean it can be executed without Session..can easily be integrated with keras and vice versa..\n",
    "#offer more flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d294526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In google colab they used most recent version of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae33c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf1 we have concept of computational graphs which were used to build models\n",
    "#Nodes n edges..edges r datapoints n nodes were operations.\n",
    "#We run computational graph in session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4ba83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /temp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /temp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /temp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /temp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets(\"/temp/data/\",one_hot=True)\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9afb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "learning_rate=0.1\n",
    "num_steps=500\n",
    "batch_size=120\n",
    "display_step=100\n",
    "#no of steps/display_steps=epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c7cc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network Parameters\n",
    "n_hidden_1= 256 #1st layer number of neurons\n",
    "n_hidden_2= 256 #2nd layer number of neurons\n",
    "num_input= 784 #MNIST data input (img shape: 28*28)\n",
    "num_classes=10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "#tf Graph input\n",
    "X=tf.placeholder(\"float\",[None,num_input])\n",
    "Y=tf.placeholder(\"float\",[None,num_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64c211d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store layers weights and bias\n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    \"h2\":tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    \"out\":tf.Variable(tf.random_normal([n_hidden_2,num_classes]))\n",
    "}\n",
    "\n",
    "bias={\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    \"b2\":tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    \"out\":tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e7e6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Model\n",
    "def neural_net(x):\n",
    "    #Hidden layer fully connected layer with 256 neurons\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),bias[\"b1\"])\n",
    "    #Hidden layer fully connected layer with 256 neurons\n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights[\"h2\"]),bias[\"b2\"])\n",
    "    #Ouput fully connected layer with a neuron for each class\n",
    "    out_layer=tf.matmul(layer_2,weights[\"out\"])+bias[\"out\"]\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35cc8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct model\n",
    "logits=neural_net(X)\n",
    "\n",
    "#Define loss and optimizer\n",
    "loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op=optimizer.minimize(loss_op)\n",
    "\n",
    "#evaluate the model (with test logits, for dropout to be disabled)\n",
    "correct_pred=tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "#initialize  the variables (i.e assign their default value)\n",
    "init=tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07b8ccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, minibatch Loss= 8554.7080, Training accuracy= 0.483\n",
      "Step 100, minibatch Loss= 427.5001, Training accuracy= 0.833\n",
      "Step 200, minibatch Loss= 86.0255, Training accuracy= 0.942\n",
      "Step 300, minibatch Loss= 143.9464, Training accuracy= 0.908\n",
      "Step 400, minibatch Loss= 26.5477, Training accuracy= 0.925\n",
      "Step 500, minibatch Loss= 33.0546, Training accuracy= 0.925\n",
      "optimization finished\n",
      "test accuracy 0.8661\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        #run optimization op(backprop)\n",
    "        sess.run(train_op,feed_dict={X:batch_x,Y:batch_y})\n",
    "        if step%display_step==0 or step==1:\n",
    "            #calculate the batch loss and accuracy\n",
    "            loss,acc=sess.run([loss_op,accuracy],feed_dict={X:batch_x, Y:batch_y})\n",
    "            print(\"Step \" + str(step) + \", minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "            \n",
    "    print(\"optimization finished\")\n",
    "\n",
    "    #calculate accuracy to Mnist test image\n",
    "    print(\"test accuracy\",sess.run(accuracy,feed_dict={X:mnist.test.images,Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc1a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
